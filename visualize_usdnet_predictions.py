"""
================================================================================
USDNet å¯è§†åŒ–ç¨‹åº - é€‚é…Zarræ•°æ®å’Œè®­ç»ƒå¥½çš„æ¨¡å‹
================================================================================

åŠŸèƒ½ï¼š
1. åŠ è½½è®­ç»ƒå¥½çš„USDNetæ¨¡å‹
2. ä»Zarræ–‡ä»¶è¯»å–ç‚¹äº‘æ•°æ®
3. æ¨ç†é¢„æµ‹è¯­ä¹‰æ ‡ç­¾
4. å¯è§†åŒ–ï¼šGround Truth vs Prediction
5. ç”ŸæˆHTMLäº¤äº’å¼å¯è§†åŒ–

ä½¿ç”¨æ–¹æ³•ï¼š
python visualize_usdnet_predictions.py \
    --checkpoint ./c6/finetune/ckpt_best.pt \
    --zarr_root ./td5 \
    --scene_id <scene_id> \
    --output_dir ./visualizations

================================================================================
"""

import os
import sys
import argparse
import json
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import logging

import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import MinkowskiEngine as ME
import zarr
from tqdm import tqdm

try:
    import open3d as o3d
    HAS_OPEN3D = True
except ImportError:
    HAS_OPEN3D = False
    print("âš ï¸  Open3Dæœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨Open3Då¯è§†åŒ–")

try:
    import plotly.graph_objects as go
    from plotly.subplots import make_subplots
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False
    print("âš ï¸  Plotlyæœªå®‰è£…ï¼Œæ— æ³•ç”ŸæˆHTMLå¯è§†åŒ–")

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


# ============================================================================
# é…è‰²æ–¹æ¡ˆ
# ============================================================================

class ColorPalette:
    """ç±»åˆ«é¢œè‰²æ˜ å°„"""
    
    @staticmethod
    def generate_colors(num_classes: int) -> np.ndarray:
        """ç”ŸæˆåŒºåˆ†åº¦é«˜çš„é¢œè‰²"""
        np.random.seed(42)
        colors = np.random.rand(num_classes, 3)
        colors = (colors * 255).astype(np.uint8)
        return colors
    
    @staticmethod
    def get_semantic_colors(num_classes: int) -> Dict[int, Tuple[int, int, int]]:
        """è¿”å›ç±»åˆ«IDåˆ°RGBé¢œè‰²çš„æ˜ å°„"""
        colors = ColorPalette.generate_colors(num_classes)
        return {i: tuple(colors[i]) for i in range(num_classes)}


# ============================================================================
# æ¨¡å‹å®šä¹‰ï¼ˆä¸train_usdnet_complete.pyç›¸åŒï¼‰
# ============================================================================

class MinkowskiBasicBlock(nn.Module):
    expansion = 1
    
    def __init__(self, in_channels: int, out_channels: int, stride: int = 1, 
                 dilation: int = 1, bn_momentum: float = 0.1):
        super().__init__()
        
        self.conv1 = ME.MinkowskiConvolution(
            in_channels=in_channels, out_channels=out_channels,
            kernel_size=3, stride=stride, dilation=dilation, dimension=3,
        )
        self.bn1 = ME.MinkowskiBatchNorm(out_channels, momentum=bn_momentum)
        
        self.conv2 = ME.MinkowskiConvolution(
            in_channels=out_channels, out_channels=out_channels,
            kernel_size=3, stride=1, dilation=dilation, dimension=3,
        )
        self.bn2 = ME.MinkowskiBatchNorm(out_channels, momentum=bn_momentum)
        
        self.relu = ME.MinkowskiReLU(inplace=True)
        
        self.downsample = None
        if stride != 1 or in_channels != out_channels:
            self.downsample = nn.Sequential(
                ME.MinkowskiConvolution(
                    in_channels=in_channels, out_channels=out_channels,
                    kernel_size=1, stride=stride, dimension=3,
                ),
                ME.MinkowskiBatchNorm(out_channels, momentum=bn_momentum),
            )
    
    def forward(self, x: ME.SparseTensor) -> ME.SparseTensor:
        identity = x
        
        out = self.conv1(x)
        out = self.bn1(out)
        out = self.relu(out)
        
        out = self.conv2(out)
        out = self.bn2(out)
        
        if self.downsample is not None:
            identity = self.downsample(x)
        
        out = out + identity
        out = self.relu(out)
        
        return out


class Res16UNetBackbone(nn.Module):
    BLOCK = MinkowskiBasicBlock
    PLANES = (32, 64, 128, 256, 128, 128, 96, 96)
    LAYERS = (2, 2, 2, 2, 2, 2, 2, 2)
    INIT_DIM = 32
    
    def __init__(self, in_channels: int = 9, out_channels: int = 256, bn_momentum: float = 0.1):
        super().__init__()
        
        self.inplanes = self.INIT_DIM
        self.relu = ME.MinkowskiReLU(inplace=True)
        
        self.conv0p1s1 = ME.MinkowskiConvolution(
            in_channels=in_channels, out_channels=self.INIT_DIM,
            kernel_size=3, stride=1, dimension=3,
        )
        self.bn0 = ME.MinkowskiBatchNorm(self.INIT_DIM, momentum=bn_momentum)
        
        self.conv1p1s2 = ME.MinkowskiConvolution(
            in_channels=self.INIT_DIM, out_channels=self.INIT_DIM,
            kernel_size=2, stride=2, dimension=3,
        )
        self.bn1 = ME.MinkowskiBatchNorm(self.INIT_DIM, momentum=bn_momentum)
        self.block1 = self._make_layer(self.INIT_DIM, self.PLANES[0], self.LAYERS[0], bn_momentum)
        
        self.conv2p2s2 = ME.MinkowskiConvolution(
            in_channels=self.inplanes, out_channels=self.inplanes,
            kernel_size=2, stride=2, dimension=3,
        )
        self.bn2 = ME.MinkowskiBatchNorm(self.inplanes, momentum=bn_momentum)
        self.block2 = self._make_layer(self.inplanes, self.PLANES[1], self.LAYERS[1], bn_momentum)
        
        self.conv3p4s2 = ME.MinkowskiConvolution(
            in_channels=self.inplanes, out_channels=self.inplanes,
            kernel_size=2, stride=2, dimension=3,
        )
        self.bn3 = ME.MinkowskiBatchNorm(self.inplanes, momentum=bn_momentum)
        self.block3 = self._make_layer(self.inplanes, self.PLANES[2], self.LAYERS[2], bn_momentum)
        
        self.conv4p8s2 = ME.MinkowskiConvolution(
            in_channels=self.inplanes, out_channels=self.inplanes,
            kernel_size=2, stride=2, dimension=3,
        )
        self.bn4 = ME.MinkowskiBatchNorm(self.inplanes, momentum=bn_momentum)
        self.block4 = self._make_layer(self.inplanes, self.PLANES[3], self.LAYERS[3], bn_momentum)
        
        self.convtr4p16s2 = ME.MinkowskiConvolutionTranspose(
            in_channels=self.inplanes, out_channels=self.PLANES[4],
            kernel_size=2, stride=2, dimension=3,
        )
        self.bntr4 = ME.MinkowskiBatchNorm(self.PLANES[4], momentum=bn_momentum)
        self.inplanes = self.PLANES[4] + self.PLANES[2] * self.BLOCK.expansion
        self.block5 = self._make_layer(self.inplanes, self.PLANES[4], self.LAYERS[4], bn_momentum)
        
        self.convtr5p8s2 = ME.MinkowskiConvolutionTranspose(
            in_channels=self.inplanes, out_channels=self.PLANES[5],
            kernel_size=2, stride=2, dimension=3,
        )
        self.bntr5 = ME.MinkowskiBatchNorm(self.PLANES[5], momentum=bn_momentum)
        self.inplanes = self.PLANES[5] + self.PLANES[1] * self.BLOCK.expansion
        self.block6 = self._make_layer(self.inplanes, self.PLANES[5], self.LAYERS[5], bn_momentum)
        
        self.convtr6p4s2 = ME.MinkowskiConvolutionTranspose(
            in_channels=self.inplanes, out_channels=self.PLANES[6],
            kernel_size=2, stride=2, dimension=3,
        )
        self.bntr6 = ME.MinkowskiBatchNorm(self.PLANES[6], momentum=bn_momentum)
        self.inplanes = self.PLANES[6] + self.PLANES[0] * self.BLOCK.expansion
        self.block7 = self._make_layer(self.inplanes, self.PLANES[6], self.LAYERS[6], bn_momentum)
        
        self.convtr7p2s2 = ME.MinkowskiConvolutionTranspose(
            in_channels=self.inplanes, out_channels=self.PLANES[7],
            kernel_size=2, stride=2, dimension=3,
        )
        self.bntr7 = ME.MinkowskiBatchNorm(self.PLANES[7], momentum=bn_momentum)
        self.inplanes = self.PLANES[7] + self.INIT_DIM
        self.block8 = self._make_layer(self.inplanes, self.PLANES[7], self.LAYERS[7], bn_momentum)
        
        self.final = ME.MinkowskiConvolution(
            in_channels=self.inplanes, out_channels=out_channels,
            kernel_size=1, stride=1, dimension=3,
        )
    
    def _make_layer(self, in_channels, out_channels, blocks, bn_momentum):
        layers = []
        layers.append(MinkowskiBasicBlock(in_channels, out_channels, stride=1, bn_momentum=bn_momentum))
        self.inplanes = out_channels * self.BLOCK.expansion
        for _ in range(1, blocks):
            layers.append(MinkowskiBasicBlock(self.inplanes, out_channels, stride=1, bn_momentum=bn_momentum))
        return nn.Sequential(*layers)
    
    def forward(self, x: ME.SparseTensor) -> ME.SparseTensor:
        out = self.conv0p1s1(x)
        out = self.bn0(out)
        out_p1 = self.relu(out)
        
        out = self.conv1p1s2(out_p1)
        out = self.bn1(out)
        out = self.relu(out)
        out_b1p2 = self.block1(out)
        
        out = self.conv2p2s2(out_b1p2)
        out = self.bn2(out)
        out = self.relu(out)
        out_b2p4 = self.block2(out)
        
        out = self.conv3p4s2(out_b2p4)
        out = self.bn3(out)
        out = self.relu(out)
        out_b3p8 = self.block3(out)
        
        out = self.conv4p8s2(out_b3p8)
        out = self.bn4(out)
        out = self.relu(out)
        out = self.block4(out)
        
        out = self.convtr4p16s2(out)
        out = self.bntr4(out)
        out = self.relu(out)
        out = ME.cat(out, out_b3p8)
        out = self.block5(out)
        
        out = self.convtr5p8s2(out)
        out = self.bntr5(out)
        out = self.relu(out)
        out = ME.cat(out, out_b2p4)
        out = self.block6(out)
        
        out = self.convtr6p4s2(out)
        out = self.bntr6(out)
        out = self.relu(out)
        out = ME.cat(out, out_b1p2)
        out = self.block7(out)
        
        out = self.convtr7p2s2(out)
        out = self.bntr7(out)
        out = self.relu(out)
        out = ME.cat(out, out_p1)
        out = self.block8(out)
        
        feat_3d = self.final(out)
        
        return feat_3d


class USDNetStudent(nn.Module):
    def __init__(self, num_classes: int, feature_dim_3d: int = 256, 
                 feature_dim_2d: int = 768, bn_momentum: float = 0.1, dropout: float = 0.1):
        super().__init__()
        
        self.num_classes = num_classes
        self.feature_dim_3d = feature_dim_3d
        self.feature_dim_2d = feature_dim_2d
        
        self.backbone = Res16UNetBackbone(
            in_channels=9, out_channels=feature_dim_3d, bn_momentum=bn_momentum,
        )
        
        self.distill_head = nn.Sequential(
            ME.MinkowskiLinear(feature_dim_3d, 512),
            ME.MinkowskiBatchNorm(512),
            ME.MinkowskiReLU(inplace=True),
            ME.MinkowskiDropout(p=dropout),
            ME.MinkowskiLinear(512, feature_dim_2d),
        )
        
        self.seg_head = nn.Sequential(
            ME.MinkowskiLinear(feature_dim_3d, 128),
            ME.MinkowskiBatchNorm(128),
            ME.MinkowskiReLU(inplace=True),
            ME.MinkowskiDropout(p=dropout),
            ME.MinkowskiLinear(128, num_classes),
        )
    
    def forward(self, x: ME.SparseTensor) -> Tuple[ME.SparseTensor, ME.SparseTensor]:
        feat_3d = self.backbone(x)
        seg_logits = self.seg_head(feat_3d)
        distill_features = self.distill_head(feat_3d)
        return seg_logits, distill_features


# ============================================================================
# Zarræ•°æ®åŠ è½½
# ============================================================================

class ZarrSceneLoader:
    """ä»Zarræ–‡ä»¶åŠ è½½åœºæ™¯æ•°æ®"""
    
    @staticmethod
    def load_scene(zarr_path: Path, voxel_size: float = 0.05) -> Dict:
        """
        åŠ è½½Zarråœºæ™¯æ•°æ®
        
        Returns:
            dict with keys: points, colors, normals, semantic_labels, dino_features
        """
        logger.info(f"åŠ è½½Zarr: {zarr_path.name}")
        
        root = zarr.open(str(zarr_path), mode='r')
        
        try:
            points = np.array(root['points'][:], dtype=np.float32)
            colors = np.array(root['colors'][:], dtype=np.float32) if 'colors' in root else None
            normals = np.array(root['normals'][:], dtype=np.float32) if 'normals' in root else None
            semantic_labels = np.array(root['semantic_labels'][:], dtype=np.int32) if 'semantic_labels' in root else None
            dino_features = np.array(root['dino_features'][:], dtype=np.float32) if 'dino_features' in root else None
            valid_mask = np.array(root['valid_mask'][:], dtype=bool) if 'valid_mask' in root else np.ones(len(points), dtype=bool)
            
            # å½’ä¸€åŒ–é¢œè‰²
            if colors is not None and colors.max() > 1.0:
                colors = colors / 255.0
            
            # é»˜è®¤æ³•å‘é‡
            if normals is None:
                normals = np.zeros_like(points, dtype=np.float32)
                normals[:, 2] = 1.0
            
            logger.info(f"  - ç‚¹æ•°: {len(points):,}")
            logger.info(f"  - æœ‰æ•ˆç‚¹: {valid_mask.sum():,}")
            
            if semantic_labels is not None:
                valid_labels = semantic_labels[semantic_labels >= 0]
                logger.info(f"  - æœ‰æ•ˆæ ‡ç­¾: {len(valid_labels):,}")
                logger.info(f"  - æ ‡ç­¾èŒƒå›´: [{valid_labels.min()}, {valid_labels.max()}]")
            
            return {
                'points': points,
                'colors': colors,
                'normals': normals,
                'semantic_labels': semantic_labels,
                'dino_features': dino_features,
                'valid_mask': valid_mask,
                'voxel_size': voxel_size,
            }
        
        finally:
            root.store.close() if hasattr(root.store, 'close') else None


# ============================================================================
# æ¨ç†å¼•æ“
# ============================================================================

class InferenceEngine:
    """USDNetæ¨ç†å¼•æ“"""
    
    def __init__(self, checkpoint_path: str, device: str = 'cuda:0'):
        self.device = device
        
        logger.info(f"åŠ è½½æ¨¡å‹: {checkpoint_path}")
        
        # åŠ è½½checkpoint
        ckpt = torch.load(checkpoint_path, map_location=device)
        config = ckpt.get('config', {})
        
        self.num_classes = config.get('num_classes', 100)
        logger.info(f"  - ç±»åˆ«æ•°: {self.num_classes}")
        
        # åˆå§‹åŒ–æ¨¡å‹
        self.model = USDNetStudent(
            num_classes=self.num_classes,
            feature_dim_3d=config.get('feature_dim_3d', 256),
            feature_dim_2d=config.get('feature_dim_2d', 768),
            dropout=config.get('dropout', 0.1),
        ).to(device)
        
        # åŠ è½½æƒé‡
        self.model.load_state_dict(ckpt['model'])
        self.model.eval()
        
        logger.info(f"  âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
    
    @torch.no_grad()
    def predict(self, scene_data: Dict, chunk_size: int = 100000) -> np.ndarray:
        """
        æµå¼åˆ†å—é¢„æµ‹åœºæ™¯çš„è¯­ä¹‰æ ‡ç­¾
        
        Args:
            scene_data: ä»ZarrSceneLoader.load_scene()è¿”å›çš„å­—å…¸
            chunk_size: æ¯æ¬¡æ¨ç†çš„æœ€å¤§ç‚¹æ•°ï¼ˆé»˜è®¤100kç‚¹ï¼‰
        
        Returns:
            predictions: [N] é¢„æµ‹çš„ç±»åˆ«IDæ•°ç»„
        """
        points = scene_data['points']
        colors = scene_data['colors']
        normals = scene_data['normals']
        voxel_size = scene_data['voxel_size']
        
        num_points = len(points)
        num_chunks = int(np.ceil(num_points / chunk_size))
        
        if num_chunks > 1:
            logger.info(f"ğŸš€ å¤§åœºæ™¯æ£€æµ‹ ({num_points:,} ç‚¹)ï¼Œä½¿ç”¨åˆ†å—æ¨ç†")
            logger.info(f"  - å—å¤§å°: {chunk_size:,}")
            logger.info(f"  - æ€»å—æ•°: {num_chunks}")
        
        # åˆå§‹åŒ–é¢„æµ‹ç»“æœ
        predictions = np.full(num_points, -1, dtype=np.int32)
        
        # æµå¼åˆ†å—æ¨ç†
        for chunk_idx in range(num_chunks):
            start_idx = chunk_idx * chunk_size
            end_idx = min(start_idx + chunk_size, num_points)
            
            if num_chunks > 1:
                logger.info(f"\nğŸ“¦ æ¨ç†å— {chunk_idx+1}/{num_chunks} (ç‚¹ {start_idx:,}-{end_idx:,})...")
            
            # æå–å½“å‰å—
            chunk_points = points[start_idx:end_idx]
            chunk_colors = colors[start_idx:end_idx] if colors is not None else None
            chunk_normals = normals[start_idx:end_idx]
            
            # ä½“ç´ åŒ–å½“å‰å—
            voxel_coords = np.floor(chunk_points / voxel_size).astype(np.int32)
            unique_coords, unique_indices = np.unique(voxel_coords, axis=0, return_index=True)
            
            # åªä¿ç•™å”¯ä¸€ä½“ç´ 
            points_unique = chunk_points[unique_indices]
            colors_unique = chunk_colors[unique_indices] if chunk_colors is not None else np.ones((len(unique_indices), 3), dtype=np.float32) * 0.5
            normals_unique = chunk_normals[unique_indices]
            
            # æ„å»ºç‰¹å¾ (RGB + æ³•å‘é‡ + åæ ‡)
            combined_features = np.hstack([colors_unique, normals_unique, points_unique])
            
            # æ·»åŠ batchç´¢å¼•
            batch_indices = np.zeros((len(unique_indices), 1), dtype=np.int32)
            coords_with_batch = np.hstack([batch_indices, unique_coords])
            
            # è½¬æ¢ä¸ºTensor
            coords = torch.from_numpy(coords_with_batch).int().to(self.device)
            features = torch.from_numpy(combined_features).float().to(self.device)
            
            # åˆ›å»ºSparseTensor
            x = ME.SparseTensor(features=features, coordinates=coords, device=self.device)
            
            # æ¨ç†å½“å‰å—
            seg_logits, _ = self.model(x)
            pred_labels = seg_logits.features.argmax(dim=-1).cpu().numpy()
            
            # æ˜ å°„å›å½“å‰å—çš„åŸå§‹ç‚¹äº‘
            for i, coord in enumerate(voxel_coords):
                match_idx = np.where((unique_coords == coord).all(axis=1))[0]
                if len(match_idx) > 0:
                    predictions[start_idx + i] = pred_labels[match_idx[0]]
            
            if num_chunks > 1:
                logger.info(f"  âœ… å— {chunk_idx+1} å®Œæˆ ({end_idx-start_idx:,} ç‚¹)")
            
            # é‡Šæ”¾GPUå†…å­˜
            del coords, features, x, seg_logits
            torch.cuda.empty_cache()
        
        logger.info(f"  âœ“ æ¨ç†å®Œæˆ: {(predictions >= 0).sum():,}/{len(predictions):,} ä¸ªç‚¹")
        
        return predictions


# ============================================================================
# å¯è§†åŒ–å·¥å…·
# ============================================================================

class Visualizer:
    """ç‚¹äº‘å¯è§†åŒ–å·¥å…·"""
    
    @staticmethod
    def visualize_open3d(points: np.ndarray, colors: np.ndarray, 
                         gt_labels: Optional[np.ndarray] = None,
                         pred_labels: Optional[np.ndarray] = None,
                         class_names: Optional[List[str]] = None):
        """Open3Däº¤äº’å¼å¯è§†åŒ–"""
        
        if not HAS_OPEN3D:
            logger.error("Open3Dæœªå®‰è£…")
            return
        
        logger.info("å¯åŠ¨Open3Då¯è§†åŒ–...")
        
        # åˆ›å»ºç‚¹äº‘
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(points)
        
        if colors is not None:
            pcd.colors = o3d.utility.Vector3dVector(colors)
        
        # å¯è§†åŒ–
        o3d.visualization.draw_geometries([pcd], window_name="Point Cloud")
    
    @staticmethod
    def visualize_plotly_by_objects(points: np.ndarray, 
                                     gt_labels: np.ndarray,
                                     pred_labels: np.ndarray,
                                     class_names: List[str],
                                     output_dir: Path,
                                     scene_id: str,
                                     max_points_per_object: int = 50000):
        """
        æŒ‰ç‰©ä½“/è¯­ä¹‰åŒºåŸŸåˆ†ç»„å¯è§†åŒ–ï¼ˆæ¯ä¸ªç‰©ä½“ä¸€ä¸ªHTMLï¼‰
        
        æµå¼å¤„ç†ç­–ç•¥ï¼š
        1. æŒ‰GTæ ‡ç­¾èšç±»ï¼Œæ‰¾å‡ºæ¯ä¸ªè¯­ä¹‰ç±»åˆ«çš„æ‰€æœ‰ç‚¹
        2. å¯¹æ¯ä¸ªç±»åˆ«ï¼Œå¦‚æœç‚¹æ•°å¤ªå¤šåˆ™ç©ºé—´åˆ†å‰²ï¼ˆDBSCANæˆ–ç½‘æ ¼ï¼‰
        3. æ¯ä¸ªç‰©ä½“/åŒºåŸŸç”Ÿæˆç‹¬ç«‹HTML
        4. æµå¼å¤„ç†ï¼Œé€ä¸ªç‰©ä½“åŠ è½½å’Œé‡Šæ”¾å†…å­˜
        
        Args:
            points: ç‚¹äº‘åæ ‡ [N, 3]
            gt_labels: Ground Truthæ ‡ç­¾ [N]
            pred_labels: é¢„æµ‹æ ‡ç­¾ [N]
            class_names: ç±»åˆ«åç§°åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            scene_id: åœºæ™¯ID
            max_points_per_object: å•ä¸ªç‰©ä½“æœ€å¤§ç‚¹æ•°ï¼ˆè¶…è¿‡åˆ™ç©ºé—´åˆ†å‰²ï¼‰
        """
        
        if not HAS_PLOTLY:
            logger.error("Plotlyæœªå®‰è£…")
            return
        
        num_points = len(points)
        num_classes = len(class_names)
        
        logger.info(f"ğŸ¯ æŒ‰ç‰©ä½“åˆ†ç»„å¯è§†åŒ–...")
        logger.info(f"  - æ€»ç‚¹æ•°: {num_points:,}")
        logger.info(f"  - ç±»åˆ«æ•°: {num_classes}")
        
        color_map = ColorPalette.get_semantic_colors(num_classes)
        
        # é¢œè‰²è½¬æ¢å‡½æ•°
        def labels_to_colors(labels):
            colors = np.zeros((len(labels), 3), dtype=np.float32)
            for i, label in enumerate(labels):
                if label >= 0 and label < num_classes:
                    colors[i] = np.array(color_map[label]) / 255.0
                else:
                    colors[i] = [0.5, 0.5, 0.5]
            return colors
        
        # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„ç‚¹æ•°
        unique_labels = np.unique(gt_labels[gt_labels >= 0])
        logger.info(f"  - å‘ç° {len(unique_labels)} ä¸ªè¯­ä¹‰ç±»åˆ«")
        
        object_groups = []
        for label in unique_labels:
            mask = (gt_labels == label)
            num_pts = mask.sum()
            
            if num_pts == 0:
                continue
            
            class_name = class_names[label] if label < len(class_names) else f"class_{label}"
            
            # å¦‚æœå•ä¸ªç±»åˆ«ç‚¹æ•°å¤ªå¤šï¼ŒæŒ‰ç©ºé—´åˆ†å‰²
            if num_pts > max_points_per_object:
                # ä½¿ç”¨ç®€å•çš„ç©ºé—´ç½‘æ ¼åˆ†å‰²
                pts = points[mask]
                labels_gt = gt_labels[mask]
                labels_pred = pred_labels[mask]
                
                # è®¡ç®—ç©ºé—´èŒƒå›´
                mins = pts.min(axis=0)
                maxs = pts.max(axis=0)
                ranges = maxs - mins
                
                # ä¼°ç®—éœ€è¦å¤šå°‘ä¸ªå­åŒºåŸŸ
                num_subdivisions = int(np.ceil(num_pts / max_points_per_object))
                grid_size = int(np.ceil(num_subdivisions ** (1/3)))  # 3Dç½‘æ ¼
                
                logger.info(f"  - {class_name}: {num_pts:,} ç‚¹ â†’ ç©ºé—´åˆ†å‰²ä¸º {grid_size}Â³ ç½‘æ ¼")
                
                # ç½‘æ ¼åˆ’åˆ†
                grid_indices = np.floor((pts - mins) / (ranges / grid_size + 1e-6)).astype(int)
                grid_indices = np.clip(grid_indices, 0, grid_size - 1)
                grid_keys = [tuple(idx) for idx in grid_indices]
                
                # æŒ‰ç½‘æ ¼åˆ†ç»„
                from collections import defaultdict
                grid_groups = defaultdict(list)
                for i, key in enumerate(grid_keys):
                    grid_groups[key].append(i)
                
                # ä¸ºæ¯ä¸ªéç©ºç½‘æ ¼åˆ›å»ºobject group
                for sub_idx, (grid_key, indices) in enumerate(grid_groups.items()):
                    if len(indices) < 100:  # è¿‡æ»¤æ‰å¤ªå°çš„ç¢ç‰‡
                        continue
                    
                    object_groups.append({
                        'name': f"{class_name}_part{sub_idx+1}",
                        'label': label,
                        'indices': np.where(mask)[0][indices],
                        'num_points': len(indices)
                    })
            else:
                # å•ä¸ªç‰©ä½“
                object_groups.append({
                    'name': class_name,
                    'label': label,
                    'indices': np.where(mask)[0],
                    'num_points': num_pts
                })
                logger.info(f"  - {class_name}: {num_pts:,} ç‚¹")
        
        logger.info(f"\nğŸ“¦ æ€»å…±åˆ†ä¸º {len(object_groups)} ä¸ªç‰©ä½“/åŒºåŸŸ")
        
        # ç”Ÿæˆç´¢å¼•HTML
        index_html_path = output_dir / f"{scene_id}_objects_index.html"
        index_html_content = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>{scene_id} - ç‰©ä½“åˆ†ç»„å¯è§†åŒ–</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                h1 {{ color: #333; }}
                .object-list {{ list-style: none; padding: 0; }}
                .object-item {{ 
                    margin: 10px 0; 
                    padding: 15px; 
                    background: #f0f0f0; 
                    border-radius: 5px;
                }}
                .object-item a {{ 
                    text-decoration: none; 
                    color: #007bff; 
                    font-size: 18px;
                    font-weight: bold;
                }}
                .object-item a:hover {{ text-decoration: underline; }}
                .info {{ color: #666; margin-top: 5px; }}
                .category {{ display: inline-block; padding: 3px 10px; 
                           background: #007bff; color: white; 
                           border-radius: 3px; font-size: 12px; }}
            </style>
        </head>
        <body>
            <h1>ğŸ¯ {scene_id} - æŒ‰ç‰©ä½“åˆ†ç»„å¯è§†åŒ–</h1>
            <p><strong>æ€»ç‚¹æ•°:</strong> {num_points:,}</p>
            <p><strong>ç‰©ä½“æ•°:</strong> {len(object_groups)}</p>
            <hr>
            <ul class="object-list">
        """
        
        # æµå¼å¤„ç†æ¯ä¸ªç‰©ä½“
        for obj_idx, obj_info in enumerate(object_groups):
            logger.info(f"\nğŸ¨ å¤„ç†ç‰©ä½“ {obj_idx+1}/{len(object_groups)}: {obj_info['name']}...")
            
            # æå–ç‰©ä½“æ•°æ®
            indices = obj_info['indices']
            obj_points = points[indices].copy()
            obj_gt_labels = gt_labels[indices].copy()
            obj_pred_labels = pred_labels[indices].copy()
            
            # ç”Ÿæˆé¢œè‰²
            obj_gt_colors = labels_to_colors(obj_gt_labels)
            obj_pred_colors = labels_to_colors(obj_pred_labels)
            
            # è®¡ç®—å‡†ç¡®ç‡
            valid_mask = (obj_gt_labels >= 0) & (obj_pred_labels >= 0)
            if valid_mask.sum() > 0:
                obj_accuracy = (obj_gt_labels[valid_mask] == obj_pred_labels[valid_mask]).mean()
            else:
                obj_accuracy = 0.0
            
            # åˆ›å»ºå¯è§†åŒ–
            fig = make_subplots(
                rows=1, cols=2,
                specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],
                subplot_titles=('Ground Truth', 'Prediction')
            )
            
            # GTç‚¹äº‘
            fig.add_trace(
                go.Scatter3d(
                    x=obj_points[:, 0],
                    y=obj_points[:, 1],
                    z=obj_points[:, 2],
                    mode='markers',
                    marker=dict(
                        size=2,
                        color=['rgb({},{},{})'.format(int(c[0]*255), int(c[1]*255), int(c[2]*255)) 
                               for c in obj_gt_colors],
                    ),
                    text=[f"{class_names[l]}" if 0 <= l < num_classes else "unknown" for l in obj_gt_labels],
                    hovertemplate='<b>%{text}</b><br>X: %{x}<br>Y: %{y}<br>Z: %{z}<extra></extra>',
                ),
                row=1, col=1
            )
            
            # Predictionç‚¹äº‘
            fig.add_trace(
                go.Scatter3d(
                    x=obj_points[:, 0],
                    y=obj_points[:, 1],
                    z=obj_points[:, 2],
                    mode='markers',
                    marker=dict(
                        size=2,
                        color=['rgb({},{},{})'.format(int(c[0]*255), int(c[1]*255), int(c[2]*255)) 
                               for c in obj_pred_colors],
                    ),
                    text=[f"{class_names[l]}" if 0 <= l < num_classes else "unknown" for l in obj_pred_labels],
                    hovertemplate='<b>%{text}</b><br>X: %{x}<br>Y: %{y}<br>Z: %{z}<extra></extra>',
                ),
                row=1, col=2
            )
            
            fig.update_layout(
                title=f"{obj_info['name']} - Accuracy: {obj_accuracy*100:.1f}%",
                height=800,
                showlegend=False,
            )
            
            # ä¿å­˜HTML
            html_filename = f"{scene_id}_{obj_info['name'].replace(' ', '_')}.html"
            html_path = output_dir / html_filename
            fig.write_html(str(html_path))
            
            logger.info(f"  âœ… å·²ä¿å­˜: {html_filename} ({obj_info['num_points']:,} ç‚¹, å‡†ç¡®ç‡ {obj_accuracy*100:.1f}%)")
            
            # æ·»åŠ åˆ°ç´¢å¼•
            color_rgb = color_map[obj_info['label']]
            index_html_content += f"""
                <li class="object-item">
                    <a href="{html_filename}">ğŸ¯ {obj_info['name']}</a>
                    <div class="info">
                        <span class="category" style="background: rgb({color_rgb[0]},{color_rgb[1]},{color_rgb[2]});">
                            {class_names[obj_info['label']] if obj_info['label'] < len(class_names) else 'unknown'}
                        </span>
                        ç‚¹æ•°: {obj_info['num_points']:,} | å‡†ç¡®ç‡: {obj_accuracy*100:.1f}%
                    </div>
                </li>
            """
            
            # é‡Šæ”¾å†…å­˜
            del obj_points, obj_gt_labels, obj_pred_labels
            del obj_gt_colors, obj_pred_colors, fig
        
        # å®Œæˆç´¢å¼•HTML
        index_html_content += """
            </ul>
            <hr>
            <p style="color: #666; font-size: 14px;">ğŸ’¡ æç¤º: ç‚¹å‡»ä¸Šæ–¹é“¾æ¥æŸ¥çœ‹æ¯ä¸ªç‰©ä½“çš„åˆ†å‰²æ•ˆæœ</p>
        </body>
        </html>
        """
        
        with open(index_html_path, 'w', encoding='utf-8') as f:
            f.write(index_html_content)
        
        logger.info(f"\n  âœ… ç´¢å¼•é¡µé¢: {index_html_path}")
        logger.info(f"  âœ… å…±ç”Ÿæˆ {len(object_groups)} ä¸ªç‰©ä½“HTMLæ–‡ä»¶")
    
    @staticmethod
    def visualize_plotly(points: np.ndarray, 
                         gt_labels: np.ndarray,
                         pred_labels: np.ndarray,
                         class_names: List[str],
                         output_path: Path):
        """Plotly HTMLå¯è§†åŒ–ï¼ˆGT vs Predictionï¼‰- å•æ–‡ä»¶ç‰ˆæœ¬"""
        
        if not HAS_PLOTLY:
            logger.error("Plotlyæœªå®‰è£…")
            return
        
        logger.info("ç”ŸæˆPlotly HTMLå¯è§†åŒ–ï¼ˆå•æ–‡ä»¶ï¼‰...")
        
        num_classes = len(class_names)
        color_map = ColorPalette.get_semantic_colors(num_classes)
        
        # ä¸ºGTå’ŒPredç”Ÿæˆé¢œè‰²
        def labels_to_colors(labels):
            colors = np.zeros((len(labels), 3), dtype=np.float32)
            for i, label in enumerate(labels):
                if label >= 0 and label < num_classes:
                    colors[i] = np.array(color_map[label]) / 255.0
                else:
                    colors[i] = [0.5, 0.5, 0.5]  # ç°è‰²è¡¨ç¤ºæ— æ•ˆ
            return colors
        
        gt_colors = labels_to_colors(gt_labels)
        pred_colors = labels_to_colors(pred_labels)
        
        # åˆ›å»ºå­å›¾
        fig = make_subplots(
            rows=1, cols=2,
            specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],
            subplot_titles=('Ground Truth', 'Prediction')
        )
        
        # GTç‚¹äº‘
        fig.add_trace(
            go.Scatter3d(
                x=points[:, 0],
                y=points[:, 1],
                z=points[:, 2],
                mode='markers',
                marker=dict(
                    size=1,
                    color=['rgb({},{},{})'.format(int(c[0]*255), int(c[1]*255), int(c[2]*255)) 
                           for c in gt_colors],
                ),
                text=[f"{class_names[l]}" if 0 <= l < num_classes else "unknown" for l in gt_labels],
                hovertemplate='<b>%{text}</b><br>X: %{x}<br>Y: %{y}<br>Z: %{z}<extra></extra>',
            ),
            row=1, col=1
        )
        
        # Predictionç‚¹äº‘
        fig.add_trace(
            go.Scatter3d(
                x=points[:, 0],
                y=points[:, 1],
                z=points[:, 2],
                mode='markers',
                marker=dict(
                    size=1,
                    color=['rgb({},{},{})'.format(int(c[0]*255), int(c[1]*255), int(c[2]*255)) 
                           for c in pred_colors],
                ),
                text=[f"{class_names[l]}" if 0 <= l < num_classes else "unknown" for l in pred_labels],
                hovertemplate='<b>%{text}</b><br>X: %{x}<br>Y: %{y}<br>Z: %{z}<extra></extra>',
            ),
            row=1, col=2
        )
        
        fig.update_layout(
            title="USDNet Semantic Segmentation Results",
            height=800,
            showlegend=False,
        )
        
        # ä¿å­˜HTML
        fig.write_html(str(output_path))
        logger.info(f"  âœ“ å·²ä¿å­˜: {output_path}")


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

def main():
    parser = argparse.ArgumentParser(description="USDNetå¯è§†åŒ–ç¨‹åº")
    
    parser.add_argument('--checkpoint', type=str, required=True, help='æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--zarr_root', type=str, required=True, help='Zarræ•°æ®æ ¹ç›®å½•')
    parser.add_argument('--scene_id', type=str, default=None, help='åœºæ™¯IDï¼ˆä¸æŒ‡å®šåˆ™å¤„ç†ç¬¬ä¸€ä¸ªï¼‰')
    parser.add_argument('--output_dir', type=str, default='./visualizations', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--device', type=str, default='cuda:0', help='è®¾å¤‡')
    parser.add_argument('--voxel_size', type=float, default=0.05, help='ä½“ç´ å¤§å°')
    parser.add_argument('--max_points', type=int, default=None, help='æœ€å¤§æ˜¾ç¤ºç‚¹æ•°ï¼ˆNone=ä¸é™åˆ¶ï¼‰')
    parser.add_argument('--infer_chunk_size', type=int, default=100000, help='æ¨ç†åˆ†å—å¤§å°ï¼ˆç‚¹æ•°/å—ï¼‰')
    parser.add_argument('--max_points_per_object', type=int, default=50000, help='å•ä¸ªç‰©ä½“æœ€å¤§ç‚¹æ•°ï¼ˆè¶…è¿‡åˆ™ç©ºé—´åˆ†å‰²ï¼‰')
    parser.add_argument('--use_open3d', action='store_true', help='ä½¿ç”¨Open3Då¯è§†åŒ–')
    
    args = parser.parse_args()
    
    logger.info("="*80)
    logger.info("USDNet å¯è§†åŒ–ç¨‹åº")
    logger.info("="*80)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # åŠ è½½å…¨å±€æ ‡ç­¾æ˜ å°„
    zarr_root = Path(args.zarr_root)
    mapping_file = zarr_root / "global_label_mapping.json"
    
    if not mapping_file.exists():
        logger.error(f"âŒ æœªæ‰¾åˆ°å…¨å±€æ ‡ç­¾æ˜ å°„: {mapping_file}")
        return
    
    with open(mapping_file, 'r') as f:
        label_data = json.load(f)
    
    class_names = label_data['class_names']
    num_classes = label_data['num_classes']
    
    logger.info(f"âœ“ å…¨å±€ç±»åˆ«æ•°: {num_classes}")
    
    # æ‰¾åˆ°Zarræ–‡ä»¶
    zarr_files = sorted(zarr_root.glob("*_dino_patch_level.zarr"))
    
    if not zarr_files:
        logger.error(f"âŒ æœªæ‰¾åˆ°Zarræ–‡ä»¶: {zarr_root}")
        return
    
    # é€‰æ‹©åœºæ™¯
    if args.scene_id:
        zarr_path = zarr_root / f"{args.scene_id}_dino_patch_level.zarr"
        if not zarr_path.exists():
            logger.error(f"âŒ æœªæ‰¾åˆ°åœºæ™¯: {args.scene_id}")
            return
    else:
        zarr_path = zarr_files[0]
        logger.info(f"ä½¿ç”¨ç¬¬ä¸€ä¸ªåœºæ™¯: {zarr_path.stem}")
    
    scene_id = zarr_path.stem.replace('_dino_patch_level', '')
    
    # åŠ è½½åœºæ™¯æ•°æ®
    scene_data = ZarrSceneLoader.load_scene(zarr_path, voxel_size=args.voxel_size)
    
    points = scene_data['points']
    gt_labels = scene_data['semantic_labels']
    
    # é™é‡‡æ ·ï¼ˆå¦‚æœæŒ‡å®šäº†max_pointsä¸”ç‚¹å¤ªå¤šï¼‰
    if args.max_points is not None and len(points) > args.max_points:
        logger.info(f"é™é‡‡æ ·: {len(points):,} â†’ {args.max_points:,}")
        idx = np.random.choice(len(points), args.max_points, replace=False)
        points = points[idx]
        gt_labels = gt_labels[idx] if gt_labels is not None else None
        
        # æ›´æ–°scene_data
        scene_data['points'] = points
        if scene_data['colors'] is not None:
            scene_data['colors'] = scene_data['colors'][idx]
        if scene_data['normals'] is not None:
            scene_data['normals'] = scene_data['normals'][idx]
    else:
        logger.info(f"ä½¿ç”¨å…¨éƒ¨ç‚¹: {len(points):,}")
    
    # åŠ è½½æ¨¡å‹å¹¶æ¨ç†
    engine = InferenceEngine(args.checkpoint, device=args.device)
    
    logger.info(f"\n{'='*80}")
    logger.info("ğŸš€ æ¨ç†åœºæ™¯è¯­ä¹‰æ ‡ç­¾")
    logger.info(f"{'='*80}")
    
    pred_labels = engine.predict(scene_data, chunk_size=args.infer_chunk_size)
    
    # æŒ‰ç‰©ä½“åˆ†ç»„å¯è§†åŒ–
    Visualizer.visualize_plotly_by_objects(
        points=points,
        gt_labels=gt_labels,
        pred_labels=pred_labels,
        class_names=class_names,
        output_dir=output_dir,
        scene_id=scene_id,
        max_points_per_object=args.max_points_per_object
    )
    
    logger.info("\nâœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()
